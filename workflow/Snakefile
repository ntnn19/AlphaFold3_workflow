import string
import pandas as pd
import os
import yaml
localrules: PREPROCESSING , MERGE_MONO_AND_MULTI_JSON, CREATE_AF3_INFERENCE_JOBS_SPEEDY_AF3_PIPELINE, AGG_AF3_INFERENCE_JOBS, SPLIT_INFERENCE_JOB_LIST
scattergather:
    split=config.get("n_splits",1),
    split_ost=config.get("n_splits_ost",1)
SPLIT_TOTAL = workflow._scatter["split"]
SPLIT_OST = workflow._scatter["split_ost"]
WORKFLOW_DIR = workflow.basedir
print("WORKFLOW_DIR=", WORKFLOW_DIR)
WORKFLOW_DIR = workflow.source_path(".")

print("WORKFLOW_DIR=", WORKFLOW_DIR)
WORKFLOW_DIR = workflow.workdir_init

print("WORKFLOW_DIR=", WORKFLOW_DIR)
WORKFLOW_DIR = os.path.dirname(os.path.abspath(workflow.snakefile))

print("WORKFLOW_DIR=", WORKFLOW_DIR)
#exit()
INPUT_DF = config["input_csv"]
OUTPUT_DIR = config["output_dir"]
MODE = config.get("mode","default")
OST_CONTAINER = config.get("ost_container",None)
MUTUALLY_EXCLUSIVE =config.get("mutually_exclusive","all") 
GROUND_TRUTH =config.get("ground_truth",None) 
TASK = config.get("task", "")

DF = pd.read_csv(INPUT_DF)
#SEEDS = (DF["model_seeds"].astype(str).str.split(",").values[0] 
#         if "model_seeds" in DF.columns 
#         else ["1"])
if "model_seeds" in DF.columns:
    DF["model_seeds"] = DF["model_seeds"] = DF.model_seeds.astype(str)
SEEDS= DF["model_seeds"].str.split(",").values[0] if "model_seeds" in DF.columns else [1]
MSA_OPTION = config.get("msa_option","auto")
AF3_CONTAINER = config["af3_flags"]["--af3_container"]
def get_af3_flag_value(flag, default_value):
    return config.get('alphafold3_flags', {}).get(flag, default_value)

BUCKETS = get_af3_flag_value('--buckets', '256,512,768,1024,1280,1536,2048,2560,3072,3584,4096,4608,5120')
CONFORMER_MAX_ITERATIONS = get_af3_flag_value('--conformer_max_iterations', 100)
FLASH_ATTENTION_IMPLEMENTATION = get_af3_flag_value('--flash_attention_implementation', 'triton')
GPU_DEVICE = get_af3_flag_value('--gpu_device', 0)
HMMALIGN_BINARY_PATH = get_af3_flag_value('--hmmalign_binary_path', '/hmmer/bin/hmmalign')
HMMBUILD_BINARY_PATH = get_af3_flag_value('--hmmbuild_binary_path', '/hmmer/bin/hmmbuild')
HMMSEARCH_BINARY_PATH = get_af3_flag_value('--hmmsearch_binary_path', '/hmmer/bin/hmmsearch')
JACKHMMER_BINARY_PATH = get_af3_flag_value('--jackhmmer_binary_path', '/hmmer/bin/jackhmmer')
JACKHMMER_N_CPU = get_af3_flag_value('--jackhmmer_n_cpu', 8)
JAX_COMPILATION_CACHE_DIR = get_af3_flag_value('--jax_compilation_cache_dir', '/path/to/cache')
MAX_TEMPLATE_DATE = get_af3_flag_value('--max_template_date', '2021-09-30')
MGNIFY_DATABASE_PATH = get_af3_flag_value('--mgnify_database_path', os.path.join('/root/public_databases','mgy_clusters_2022_05.fa'))
NHMMER_BINARY_PATH = get_af3_flag_value('--nhmmer_binary_path', '/hmmer/bin/nhmmer')
NHMMER_N_CPU = get_af3_flag_value('--nhmmer_n_cpu', 8)
NTRNA_DATABASE_PATH = get_af3_flag_value('--ntrna_database_path', os.path.join('/root/public_databases','nt_rna_2023_02_23_clust_seq_id_90_cov_80_rep_seq.fasta'))
NUM_DIFFUSION_SAMPLES = get_af3_flag_value('--num_diffusion_samples', 5)
NUM_RECYCLES = get_af3_flag_value('--num_recycles', 10)
if "--num_seeds" in config["af3_flags"]:
    NUM_SEEDS_ARG = f"--num_seeds={config['af3_flags']['--num_seeds']}"
else:
    NUM_SEEDS_ARG = f""

PDB_DATABASE_PATH = get_af3_flag_value('--pdb_database_path', os.path.join('/root/public_databases','mmcif_files'))
RFAM_DATABASE_PATH = get_af3_flag_value('--rfam_database_path', os.path.join('/root/public_databases','rfam_14_9_clust_seq_id_90_cov_80_rep_seq.fasta'))
RNA_CENTRAL_DATABASE_PATH = get_af3_flag_value('--rna_central_database_path', os.path.join('/root/public_databases','rnacentral_active_seq_id_90_cov_80_linclust.fasta'))
SAVE_EMBEDDINGS = get_af3_flag_value('--save_embeddings', False)
SEQRES_DATABASE_PATH = get_af3_flag_value('--seqres_database_path', os.path.join('/root/public_databases','pdb_seqres_2022_09_28.fasta'))
SMALL_BFD_DATABASE_PATH = get_af3_flag_value('--small_bfd_database_path', os.path.join('/root/public_databases','bfd-first_non_consensus_sequences.fasta'))
UNIPROT_CLUSTER_ANNOT_DATABASE_PATH = get_af3_flag_value('--uniprot_cluster_annot_database_path', os.path.join('/root/public_databases','uniprot_all_2021_04.fa'))
UNIREF90_DATABASE_PATH = get_af3_flag_value('--uniref90_database_path', os.path.join('/root/public_databases','uniref90_2022_05.fa'))

def sanitised_name(name):
    """Returns sanitised version of the name that can be used as a filename."""
    lower_spaceless_name = name.lower().replace(' ', '_')
    allowed_chars = set(string.ascii_lowercase + string.digits + '_-.')
    return ''.join(l for l in lower_spaceless_name if l in allowed_chars)

def get_ground_truth_files(wildcards):
    data = ground_truth_data[sanitised_name(wildcards.multi).split("_")[0]]
    return {
        "cif": data["ground_truth_cif"],
        "sdf": data["ground_truth_sdf"]
    }


def get_preprocessing_outputs(wildcards):
    PREPROCESSING_DIR = checkpoints.PREPROCESSING.get(**wildcards).output[0]
    JOB_NAMES, = glob_wildcards(os.path.join(PREPROCESSING_DIR, "{i}.json"))
    return list(expand(os.path.join(PREPROCESSING_DIR,"{i}.json"),i=JOB_NAMES))

def get_individual_jobs(wildcards):
    PREPROCESSING_DIR = checkpoints.PREPROCESSING.get(**wildcards).output[0]
    JOB_NAMES, = glob_wildcards(os.path.join(PREPROCESSING_DIR, "{i}.json"))
    return list(expand(os.path.join(OUTPUT_DIR,"CREATE_AF3_INFERENCE_JOBS","{i}_af3_inference_job.txt"),i=JOB_NAMES))

def get_data_pipeline_outputs(wildcards):
    PREPROCESSING_DIR = checkpoints.PREPROCESSING.get(**wildcards).output[0]
    JOB_NAMES, = glob_wildcards(os.path.join(PREPROCESSING_DIR,"{i}.json"))
    return list(expand(os.path.join(OUTPUT_DIR,"AF3_DATA_PIPELINE","{i}/{i}_data.json"),i=JOB_NAMES))

def get_multimeric_json_outputs(wildcards):
    PREPROCESSING_DIR = checkpoints.PREPROCESSING.get(**wildcards).output[0]
    JOB_NAMES_MULTIMERS, = glob_wildcards(os.path.join(PREPROCESSING_DIR,"multimers","{multi}.json"))
    return list(expand(os.path.join(PREPROCESSING_DIR,"multimers","{multi}.json"),multi=JOB_NAMES_MULTIMERS)) + list(expand(os.path.join(OUTPUT_DIR,"MERGE_MONO_AND_MULTI_JSON","{multi}","{multi}_data.json"), multi=JOB_NAMES_MULTIMERS))

def get_monomeric_json_outputs(wildcards):
    PREPROCESSING_DIR = checkpoints.PREPROCESSING.get(**wildcards).output[0]
    JOB_NAMES_MONOMERS, = glob_wildcards(os.path.join(PREPROCESSING_DIR,"monomers","{mono}.json"))
    print("JOB_NAMES_MONOMERS=",JOB_NAMES_MONOMERS)
    return list(expand(os.path.join(OUTPUT_DIR,"AF3_DATA_PIPELINE_TEST","monomers","{mono}/{mono}_data.json"),mono=JOB_NAMES_MONOMERS))
#    return list(expand(os.path.join(OUTPUT_DIR,"AF3_DATA_PIPELINE","monomers","{mono}/{mono}_data.json"),mono=JOB_NAMES_MONOMERS))

def get_multimeric_json_with_msas(wildcards):
    PREPROCESSING_DIR = checkpoints.PREPROCESSING.get(**wildcards).output[0]
    JOB_NAMES_MULTIMERS, = glob_wildcards(os.path.join(PREPROCESSING_DIR,"multimers","{multi}.json"))
    return list(expand(os.path.join(OUTPUT_DIR,"CREATE_AF3_INFERENCE_JOBS","{multi}_seed-{seed}_af3_inference_job.txt"), multi=JOB_NAMES_MULTIMERS,seed=SEEDS))

def get_collect_predictions(wildcards):
    GET_DONE_OUTPUTS_DIR = checkpoints.GET_DONE_OUTPUTS.get(**wildcards).output[0]
    JOB_NAMES_MULTIMERS, SEEDS_ = glob_wildcards(os.path.join(GET_DONE_OUTPUTS_DIR,"{multi}_seed-{seed}.done.txt"))
    files = list(expand(os.path.join(OUTPUT_DIR,"CREATE_OST_COMAPRE_LIGAND_STRUCTURES_JOBS","{multi}_seed-{seed}_sample-{sample}_job.txt"), multi=set(JOB_NAMES_MULTIMERS),seed=list(set(SEEDS_)), sample=[0,1,2,3,4]))
    return files


rule all:
    input:
        get_monomeric_json_outputs,
        os.path.join(OUTPUT_DIR,"AGG_OST_REPORTS","ost_report.csv") if MODE == "virtual-drug-screen" and TASK=="ost" else [],
        expand(os.path.join(OUTPUT_DIR,"OST_COMAPRE_LIGAND_STRUCTURES","done_flags",f"job_{{s}}-of-{SPLIT_OST}.done.txt"),s=list(range(1,SPLIT_OST+1))) if MODE == "virtual-drug-screen" and TASK=="ost" else [],
        expand(os.path.join(OUTPUT_DIR,"AF3_INFERENCE",f"af3_inference_jobs_{{s}}-of-{SPLIT_TOTAL}.done.txt"),s=list(range(1,SPLIT_TOTAL+1))),



checkpoint PREPROCESSING:
    input:
        INPUT_DF,
    output:
        directory(os.path.join(OUTPUT_DIR,"PREPROCESSING"))
    params:
        msa_option = MSA_OPTION,
        mode = MODE,
        mutually_exclusive = MUTUALLY_EXCLUSIVE,
        workflow_dir = workflow.source_path("scripts/create_tasks_from_dataframe.py"),
    shell:
        """
        if [[ "{params.msa_option}" == "auto" ]]; then
            python {params.workflow_dir} {input} {output} --msa-option auto_template_based --mode {params.mode} --mutually-exclusive {params.mutually_exclusive}
            python {params.workflow_dir} {input} {output} --msa-option auto_template_free --mode {params.mode} --mutually-exclusive {params.mutually_exclusive}
        fi
        if [[ "{params.msa_option}" == "auto_template_free" ]]; then
            python {params.workflow_dir} {input} {output} --msa-option auto_template_free --mode {params.mode} --mutually-exclusive {params.mutually_exclusive}
        fi
        if [[ "{params.msa_option}" == "auto_template_based" ]]; then
            python {params.workflow_dir} {input} {output} --msa-option auto_template_based --mode {params.mode} --mutually-exclusive {params.mutually_exclusive}
        fi
        if [[ "{params.msa_option}" == "custom" ]]; then
            python {params.workflow_dir} {input} {output} --mode {params.mode} --mutually-exclusive {params.mutually_exclusive}
        fi
        """


rule AF3_DATA_DEFAULT_PIPELINE:
    input:
        default = os.path.join(OUTPUT_DIR,"PREPROCESSING","{i}.json") if MODE == "xxx" else [],
    params:
        mode = MODE,
        buckets = BUCKETS,
        conformer_max_iterations = CONFORMER_MAX_ITERATIONS,
        flash_attention_implementation = FLASH_ATTENTION_IMPLEMENTATION,
        gpu_device = GPU_DEVICE,
        hmmalign_binary_path = HMMALIGN_BINARY_PATH,
        hmmbuild_binary_path = HMMBUILD_BINARY_PATH,
        hmmsearch_binary_path = HMMSEARCH_BINARY_PATH,
        jackhmmer_binary_path = JACKHMMER_BINARY_PATH,
        jackhmmer_n_cpu = JACKHMMER_N_CPU,
        jax_compilation_cache_dir = JAX_COMPILATION_CACHE_DIR,
        max_template_date = MAX_TEMPLATE_DATE,
        mgnify_database_path = MGNIFY_DATABASE_PATH,
        nhmmer_binary_path = NHMMER_BINARY_PATH,
        nhmmer_n_cpu = NHMMER_N_CPU,
        ntrna_database_path = NTRNA_DATABASE_PATH,
        num_diffusion_samples = NUM_DIFFUSION_SAMPLES,
        num_recycles = NUM_RECYCLES,
        num_seeds_arg = NUM_SEEDS_ARG,
        pdb_database_path = PDB_DATABASE_PATH,
        rfam_database_path = RFAM_DATABASE_PATH,
        rna_central_database_path = RNA_CENTRAL_DATABASE_PATH,
        save_embeddings = SAVE_EMBEDDINGS,
        seqres_database_path = SEQRES_DATABASE_PATH,
        small_bfd_database_path = SMALL_BFD_DATABASE_PATH,
        uniprot_cluster_annot_database_path = UNIPROT_CLUSTER_ANNOT_DATABASE_PATH,
        uniref90_database_path = UNIREF90_DATABASE_PATH
    output:
        data_pipeline_msa=os.path.join(OUTPUT_DIR,"AF3_DATA_PIPELINE","{i}/{i}_data.json") if MODE == "xxx" else [],
    container:
        AF3_CONTAINER
    shell:
        """
        python /app/alphafold/run_alphafold.py --json_path=/root/af_output/PREPROCESSING/{wildcards.i}.json \
        --model_dir=/root/models \
        --output_dir=/root/af_output/AF3_DATA_PIPELINE \
        --db_dir=/root/public_databases \
        --run_data_pipeline=true \
        --run_inference=false \
        --buckets={params.buckets} \
        --conformer_max_iterations={params.conformer_max_iterations} \
        --flash_attention_implementation={params.flash_attention_implementation} \
        --gpu_device={params.gpu_device} \
        --hmmalign_binary_path={params.hmmalign_binary_path} \
        --hmmbuild_binary_path={params.hmmbuild_binary_path} \
        --hmmsearch_binary_path={params.hmmsearch_binary_path} \
        --jackhmmer_binary_path={params.jackhmmer_binary_path} \
        --jackhmmer_n_cpu={params.jackhmmer_n_cpu} \
        --jax_compilation_cache_dir={params.jax_compilation_cache_dir} \
        --max_template_date={params.max_template_date} \
        --mgnify_database_path={params.mgnify_database_path} \
        --nhmmer_binary_path={params.nhmmer_binary_path} \
        --nhmmer_n_cpu={params.nhmmer_n_cpu} \
        --ntrna_database_path={params.ntrna_database_path} \
        --num_diffusion_samples={params.num_diffusion_samples} \
        --num_recycles={params.num_recycles} \
        {params.num_seeds_arg} \
        --pdb_database_path={params.pdb_database_path} \
        --rfam_database_path={params.rfam_database_path} \
        --rna_central_database_path={params.rna_central_database_path} \
        --save_embeddings={params.save_embeddings} \
        --seqres_database_path={params.seqres_database_path} \
        --small_bfd_database_path={params.small_bfd_database_path} \
        --uniprot_cluster_annot_database_path={params.uniprot_cluster_annot_database_path} \
        --uniref90_database_path={params.uniref90_database_path}
        """

rule AF3_DATA_SPEEDY_PIPELINE_TEST:
    input:
        monomers = os.path.join(OUTPUT_DIR,"PREPROCESSING","monomers","{mono}.json") if MODE in ["default", "all-vs-all","pulldown","virtual-drug-screen"]  else [],
    output:
        data_pipeline_monomers=touch(os.path.join(OUTPUT_DIR,"AF3_DATA_PIPELINE_TEST","monomers","{mono}/{mono}_data.json")) if MODE in [
            "default","all-vs-all", "pulldown","virtual-drug-screen"] else [],

rule AF3_DATA_SPEEDY_PIPELINE:
    input:
        monomers = os.path.join(OUTPUT_DIR,"PREPROCESSING","monomers","{mono}.json") if MODE in ["default", "all-vs-all","pulldown","virtual-drug-screen"]  else [],
    params:
        mode = MODE,
        buckets = BUCKETS,
        conformer_max_iterations = CONFORMER_MAX_ITERATIONS,
        flash_attention_implementation = FLASH_ATTENTION_IMPLEMENTATION,
        gpu_device = GPU_DEVICE,
        hmmalign_binary_path = HMMALIGN_BINARY_PATH,
        hmmbuild_binary_path = HMMBUILD_BINARY_PATH,
        hmmsearch_binary_path = HMMSEARCH_BINARY_PATH,
        jackhmmer_binary_path = JACKHMMER_BINARY_PATH,
        jackhmmer_n_cpu = JACKHMMER_N_CPU,
        jax_compilation_cache_dir = JAX_COMPILATION_CACHE_DIR,
        max_template_date = MAX_TEMPLATE_DATE,
        mgnify_database_path = MGNIFY_DATABASE_PATH,
        nhmmer_binary_path = NHMMER_BINARY_PATH,
        nhmmer_n_cpu = NHMMER_N_CPU,
        ntrna_database_path = NTRNA_DATABASE_PATH,
        num_diffusion_samples = NUM_DIFFUSION_SAMPLES,
        num_recycles = NUM_RECYCLES,
        num_seeds_arg = NUM_SEEDS_ARG,
        pdb_database_path = PDB_DATABASE_PATH,
        rfam_database_path = RFAM_DATABASE_PATH,
        rna_central_database_path = RNA_CENTRAL_DATABASE_PATH,
        save_embeddings = SAVE_EMBEDDINGS,
        seqres_database_path = SEQRES_DATABASE_PATH,
        small_bfd_database_path = SMALL_BFD_DATABASE_PATH,
        uniprot_cluster_annot_database_path = UNIPROT_CLUSTER_ANNOT_DATABASE_PATH,
        uniref90_database_path = UNIREF90_DATABASE_PATH
    output:
        data_pipeline_monomers=os.path.join(OUTPUT_DIR,"AF3_DATA_PIPELINE","monomers","{mono}/{mono}_data.json") if MODE in [
            "default","all-vs-all", "pulldown","virtual-drug-screen"] else [],
    container:
        AF3_CONTAINER
    shell:
        """
        python /app/alphafold/run_alphafold.py --json_path=/root/af_output/PREPROCESSING/monomers/{wildcards.mono}.json \
        --model_dir=/root/models \
        --output_dir=/root/af_output/AF3_DATA_PIPELINE/monomers \
        --db_dir=/root/public_databases \
        --run_data_pipeline=true \
        --run_inference=false \
        --buckets={params.buckets} \
        --conformer_max_iterations={params.conformer_max_iterations} \
        --flash_attention_implementation={params.flash_attention_implementation} \
        --gpu_device={params.gpu_device} \
        --hmmalign_binary_path={params.hmmalign_binary_path} \
        --hmmbuild_binary_path={params.hmmbuild_binary_path} \
        --hmmsearch_binary_path={params.hmmsearch_binary_path} \
        --jackhmmer_binary_path={params.jackhmmer_binary_path} \
        --jackhmmer_n_cpu={params.jackhmmer_n_cpu} \
        --jax_compilation_cache_dir={params.jax_compilation_cache_dir} \
        --max_template_date={params.max_template_date} \
        --mgnify_database_path={params.mgnify_database_path} \
        --nhmmer_binary_path={params.nhmmer_binary_path} \
        --nhmmer_n_cpu={params.nhmmer_n_cpu} \
        --ntrna_database_path={params.ntrna_database_path} \
        --num_diffusion_samples={params.num_diffusion_samples} \
        --num_recycles={params.num_recycles} \
        {params.num_seeds_arg} \
        --pdb_database_path={params.pdb_database_path} \
        --rfam_database_path={params.rfam_database_path} \
        --rna_central_database_path={params.rna_central_database_path} \
        --save_embeddings={params.save_embeddings} \
        --seqres_database_path={params.seqres_database_path} \
        --small_bfd_database_path={params.small_bfd_database_path} \
        --uniprot_cluster_annot_database_path={params.uniprot_cluster_annot_database_path} \
        --uniref90_database_path={params.uniref90_database_path}
        """


rule MERGE_MONO_AND_MULTI_JSON:
    input:
        data_pipeline_monomers = lambda wildcards: [os.path.join(OUTPUT_DIR, "AF3_DATA_PIPELINE", "monomers",f"{mono}_{msa}",f"{mono}_{msa}_data.json") for msa in (["auto_template_based", "auto_template_free"] if MSA_OPTION == "auto" else [MSA_OPTION]) for mono in wildcards.multi.split(f"_{MSA_OPTION}")[0].split("_")] if MODE in ["all-vs-all", "pulldown"] else [],       
        data_pipeline_monomers_drug_screen = lambda wildcards: [os.path.join(OUTPUT_DIR, "AF3_DATA_PIPELINE", "monomers",f"{mono}_{msa}",f"{mono}_{msa}_data.json") for msa in (["auto_template_based", "auto_template_free"] if MSA_OPTION == "auto" else [MSA_OPTION]) for mono in wildcards.multi.split(f"_{MSA_OPTION}")[0].split("_") if os.path.exists(os.path.join(OUTPUT_DIR, "PREPROCESSING", "monomers", f"{mono}_{msa}.json"))] if MODE in ["default","virtual-drug-screen"] else [],


        preprocessed_multimers = os.path.join(OUTPUT_DIR,"PREPROCESSING","multimers","{multi}.json") if MODE in ["default","all-vs-all","pulldown","virtual-drug-screen"]  else [],
    params:
        monomers_dir = os.path.join(OUTPUT_DIR,"AF3_DATA_PIPELINE","monomers"),
#        mode = MODE
    output:
        data_pipeline_msa = expand(os.path.join(OUTPUT_DIR,"MERGE_MONO_AND_MULTI_JSON","{{multi}}_seed-{seed}","{{multi}}_seed-{seed}_data.json"),seed=SEEDS) if MODE in ["default","all-vs-all","pulldown","virtual-drug-screen"] else [],
    shell:
        """
        python {WORKFLOW_DIR}/scripts/merge_mono_and_multi_jsons_speedy.py {params.monomers_dir} {input.preprocessed_multimers} {OUTPUT_DIR}/MERGE_MONO_AND_MULTI_JSON
        """


rule CREATE_AF3_INFERENCE_JOBS_DEFAULT_AF3_PIPELINE:
    input:
        data_pipeline_msa = os.path.join(OUTPUT_DIR,"AF3_DATA_PIPELINE","{i}/{i}_data.json") if MODE == "xxx" else [],
    params:
        mode = MODE,
        buckets = BUCKETS,
        conformer_max_iterations = CONFORMER_MAX_ITERATIONS,
        flash_attention_implementation = FLASH_ATTENTION_IMPLEMENTATION,
        gpu_device = GPU_DEVICE,
        hmmalign_binary_path = HMMALIGN_BINARY_PATH,
        hmmbuild_binary_path = HMMBUILD_BINARY_PATH,
        hmmsearch_binary_path = HMMSEARCH_BINARY_PATH,
        jackhmmer_binary_path = JACKHMMER_BINARY_PATH,
        jackhmmer_n_cpu = JACKHMMER_N_CPU,
        jax_compilation_cache_dir = JAX_COMPILATION_CACHE_DIR,
        max_template_date = MAX_TEMPLATE_DATE,
        mgnify_database_path = MGNIFY_DATABASE_PATH,
        nhmmer_binary_path = NHMMER_BINARY_PATH,
        nhmmer_n_cpu = NHMMER_N_CPU,
        ntrna_database_path = NTRNA_DATABASE_PATH,
        num_diffusion_samples = NUM_DIFFUSION_SAMPLES,
        num_recycles = NUM_RECYCLES,
        num_seeds_arg = NUM_SEEDS_ARG,
        pdb_database_path = PDB_DATABASE_PATH,
        rfam_database_path = RFAM_DATABASE_PATH,
        rna_central_database_path = RNA_CENTRAL_DATABASE_PATH,
        save_embeddings = SAVE_EMBEDDINGS,
        seqres_database_path = SEQRES_DATABASE_PATH,
        small_bfd_database_path = SMALL_BFD_DATABASE_PATH,
        uniprot_cluster_annot_database_path = UNIPROT_CLUSTER_ANNOT_DATABASE_PATH,
        uniref90_database_path = UNIREF90_DATABASE_PATH
    output:
        data_pipeline_msa = os.path.join(OUTPUT_DIR,"CREATE_AF3_INFERENCE_JOBS","{i}_af3_inference_job.txt") if MODE == "xxx" else [],
    shell:
        """
        json_path=/root/af_output/AF3_DATA_PIPELINE/{wildcards.i}/{wildcards.i}_data.json
        echo 'python /app/alphafold/run_alphafold.py --json_path=$json_path \
        --model_dir=/root/models \
        --output_dir=/root/af_output/AF3_INFERENCE \
        --db_dir=/root/public_databases \
        --run_data_pipeline=false \
        --run_inference=true \
        --buckets={params.buckets} \
        --conformer_max_iterations={params.conformer_max_iterations} \
        --flash_attention_implementation={params.flash_attention_implementation} \
        --gpu_device={params.gpu_device} \
        --hmmalign_binary_path={params.hmmalign_binary_path} \
        --hmmbuild_binary_path={params.hmmbuild_binary_path} \
        --hmmsearch_binary_path={params.hmmsearch_binary_path} \
        --jackhmmer_binary_path={params.jackhmmer_binary_path} \
        --jackhmmer_n_cpu={params.jackhmmer_n_cpu} \
        --jax_compilation_cache_dir={params.jax_compilation_cache_dir} \
        --max_template_date={params.max_template_date} \
        --mgnify_database_path={params.mgnify_database_path} \
        --nhmmer_binary_path={params.nhmmer_binary_path} \
        --nhmmer_n_cpu={params.nhmmer_n_cpu} \
        --ntrna_database_path={params.ntrna_database_path} \
        --num_diffusion_samples={params.num_diffusion_samples} \
        --num_recycles={params.num_recycles} \
        {params.num_seeds_arg} \
        --pdb_database_path={params.pdb_database_path} \
        --rfam_database_path={params.rfam_database_path} \
        --rna_central_database_path={params.rna_central_database_path} \
        --save_embeddings={params.save_embeddings} \
        --seqres_database_path={params.seqres_database_path} \
        --small_bfd_database_path={params.small_bfd_database_path} \
        --uniprot_cluster_annot_database_path={params.uniprot_cluster_annot_database_path} \
        --uniref90_database_path={params.uniref90_database_path}' > {output}
        """

rule CREATE_AF3_INFERENCE_JOBS_SPEEDY_AF3_PIPELINE:
    input:
        multimers = os.path.join(OUTPUT_DIR,"MERGE_MONO_AND_MULTI_JSON","{multi}","{multi}_data.json") if MODE in ["default","all-vs-all","pulldown","virtual-drug-screen"]  else []
    params:
        mode = MODE,
        buckets = BUCKETS,
        conformer_max_iterations = CONFORMER_MAX_ITERATIONS,
        flash_attention_implementation = FLASH_ATTENTION_IMPLEMENTATION,
        gpu_device = GPU_DEVICE,
        hmmalign_binary_path = HMMALIGN_BINARY_PATH,
        hmmbuild_binary_path = HMMBUILD_BINARY_PATH,
        hmmsearch_binary_path = HMMSEARCH_BINARY_PATH,
        jackhmmer_binary_path = JACKHMMER_BINARY_PATH,
        jackhmmer_n_cpu = JACKHMMER_N_CPU,
        jax_compilation_cache_dir = JAX_COMPILATION_CACHE_DIR,
        max_template_date = MAX_TEMPLATE_DATE,
        mgnify_database_path = MGNIFY_DATABASE_PATH,
        nhmmer_binary_path = NHMMER_BINARY_PATH,
        nhmmer_n_cpu = NHMMER_N_CPU,
        ntrna_database_path = NTRNA_DATABASE_PATH,
        num_diffusion_samples = NUM_DIFFUSION_SAMPLES,
        num_recycles = NUM_RECYCLES,
        num_seeds_arg = NUM_SEEDS_ARG,
        pdb_database_path = PDB_DATABASE_PATH,
        rfam_database_path = RFAM_DATABASE_PATH,
        rna_central_database_path = RNA_CENTRAL_DATABASE_PATH,
        save_embeddings = SAVE_EMBEDDINGS,
        seqres_database_path = SEQRES_DATABASE_PATH,
        small_bfd_database_path = SMALL_BFD_DATABASE_PATH,
        uniprot_cluster_annot_database_path = UNIPROT_CLUSTER_ANNOT_DATABASE_PATH,
        uniref90_database_path = UNIREF90_DATABASE_PATH
    output:
        multimers = os.path.join(OUTPUT_DIR,"CREATE_AF3_INFERENCE_JOBS","{multi}_af3_inference_job.txt") if MODE in ["default","all-vs-all","pulldown","virtual-drug-screen"]  else []
    shell:
        """
        echo 'python /app/alphafold/run_alphafold.py --json_path=/root/af_output/MERGE_MONO_AND_MULTI_JSON/{wildcards.multi}/{wildcards.multi}_data.json \
        --compress_output_dir=true \
        --model_dir=/root/models \
        --output_dir=/root/af_output/AF3_INFERENCE \
        --db_dir=/root/public_databases \
        --run_data_pipeline=false \
        --run_inference=true \
        --buckets={params.buckets} \
        --conformer_max_iterations={params.conformer_max_iterations} \
        --flash_attention_implementation={params.flash_attention_implementation} \
        --gpu_device={params.gpu_device} \
        --hmmalign_binary_path={params.hmmalign_binary_path} \
        --hmmbuild_binary_path={params.hmmbuild_binary_path} \
        --hmmsearch_binary_path={params.hmmsearch_binary_path} \
        --jackhmmer_binary_path={params.jackhmmer_binary_path} \
        --jackhmmer_n_cpu={params.jackhmmer_n_cpu} \
        --jax_compilation_cache_dir={params.jax_compilation_cache_dir} \
        --max_template_date={params.max_template_date} \
        --mgnify_database_path={params.mgnify_database_path} \
        --nhmmer_binary_path={params.nhmmer_binary_path} \
        --nhmmer_n_cpu={params.nhmmer_n_cpu} \
        --ntrna_database_path={params.ntrna_database_path} \
        --num_diffusion_samples={params.num_diffusion_samples} \
        --num_recycles={params.num_recycles} \
        {params.num_seeds_arg} \
        --pdb_database_path={params.pdb_database_path} \
        --rfam_database_path={params.rfam_database_path} \
        --rna_central_database_path={params.rna_central_database_path} \
        --save_embeddings={params.save_embeddings} \
        --seqres_database_path={params.seqres_database_path} \
        --small_bfd_database_path={params.small_bfd_database_path} \
        --uniprot_cluster_annot_database_path={params.uniprot_cluster_annot_database_path} \
        --uniref90_database_path={params.uniref90_database_path}' > {output}
        """


rule AGG_AF3_INFERENCE_JOBS:
    input:
        merged_multimer = get_multimeric_json_with_msas if MODE in ["default", "all-vs-all","pulldown","virtual-drug-screen"]  else [],
    params:
        mode = MODE
    output:
        job_list = os.path.join(OUTPUT_DIR,"AGG_AF3_INFERENCE_JOBS","af3_inference_jobs.txt")
    shell:
        """
        if [[ "{params.mode}" == "default" || "{params.mode}" == "pulldown" || "{params.mode}" == "all-vs-all" || "{params.mode}" == "virtual-drug-screen" ]]; then
                find {OUTPUT_DIR}/CREATE_AF3_INFERENCE_JOBS -type f -name '*.txt' -print0 | tar --null -T - -cf - | tar -xOf - > {output.job_list}
        fi
        """

rule SPLIT_INFERENCE_JOB_LIST:
    input:
        inference_job_list = ancient(os.path.join(OUTPUT_DIR,"AGG_AF3_INFERENCE_JOBS","af3_inference_jobs.txt"))
    params:
        split_total = SPLIT_TOTAL
    output:
        sub_job_list = scatter.split(os.path.join(OUTPUT_DIR,"SPLIT_INFERENCE_JOB_LIST","af3_inference_jobs_{scatteritem}.txt"))
    run:
        import os
        lines = open(input.inference_job_list).readlines()
        [open(output.sub_job_list[i], "w").writelines(lines[i*len(lines)//params.split_total:(i+1)*len(lines)//params.split_total + (1 if i == 3 else 0)])
         for i in range(params.split_total)]



rule AF3_INFERENCE:
    input:
        job_list = ancient(os.path.join(OUTPUT_DIR,"SPLIT_INFERENCE_JOB_LIST","af3_inference_jobs_{scatteritem}.txt")),
    output:
        touch(os.path.join(OUTPUT_DIR,"AF3_INFERENCE","af3_inference_jobs_{scatteritem}.done.txt")),
    container:
        AF3_CONTAINER
    shell:
        """
        bash /scripts/parallel.sh /root/af_output/SPLIT_INFERENCE_JOB_LIST/af3_inference_jobs_{wildcards.scatteritem}.txt
        """


checkpoint GET_DONE_OUTPUTS:
    input:
        expand(os.path.join(OUTPUT_DIR,"AF3_INFERENCE",f"af3_inference_jobs_{{s}}-of-{SPLIT_TOTAL}.done.txt"),s=list(range(1,SPLIT_TOTAL+1))),
    output:
        directory(os.path.join(OUTPUT_DIR,"GET_DONE_OUTPUTS"))
    shell:
        """
        mkdir -p {output}
        for i in {{1..{SPLIT_TOTAL}}}; do
            eval \"$(grep -- '--json_path=' {OUTPUT_DIR}/SPLIT_INFERENCE_JOB_LIST/af3_inference_jobs_${{i}}-of-{SPLIT_TOTAL}.txt  | sed -E 's/.*--json_path=\\/.*\\/([^/]+)_data\\.json.*/touch {OUTPUT_DIR}\\/GET_DONE_OUTPUTS\\/\\1.done.txt/')\";
        done
        """

rule COLLECT_AF3_PREDICTIONS:
    input:
        done_files = os.path.join(OUTPUT_DIR,"GET_DONE_OUTPUTS","{multi}_seed-{seed}.done.txt"),
        job = os.path.join(OUTPUT_DIR,"CREATE_AF3_INFERENCE_JOBS","{multi}_seed-{seed}_af3_inference_job.txt") if MODE in ["all-vs-all","pulldown","virtual-drug-screen"]  else []
    output:
        os.path.join(OUTPUT_DIR,"COLLECT_AF3_PREDICTIONS","{multi}_seed-{seed}_sample-{sample}_model.cif")
    shell:
        """
        python {WORKFLOW_DIR}/scripts/collect_predictions.py --source-dir {OUTPUT_DIR}/AF3_INFERENCE/{wildcards.multi}_seed-{wildcards.seed} --job-list {input.job} --output-dir {OUTPUT_DIR}/COLLECT_AF3_PREDICTIONS
        """

rule CREATE_OST_COMAPRE_LIGAND_STRUCTURES_JOBS:
    input:
        prediction = os.path.join(OUTPUT_DIR,"COLLECT_AF3_PREDICTIONS","{multi}_seed-{seed}_sample-{sample}_model.cif") if MODE == "virtual-drug-screen" and TASK=="ost" else [], 
        ground_truth_cif=lambda wildcards: get_ground_truth_files(wildcards)["cif"] if MODE == "virtual-drug-screen" and TASK=="ost" else [], 
        ground_truth_sdf=lambda wildcards: get_ground_truth_files(wildcards)["sdf"] if MODE == "virtual-drug-screen" and TASK=="ost" else []
    output:
        os.path.join(OUTPUT_DIR,"CREATE_OST_COMAPRE_LIGAND_STRUCTURES_JOBS","{multi}_seed-{seed}_sample-{sample}_job.txt") if MODE == "virtual-drug-screen" and TASK=="ost" else [],
    shell:
        """    
        json_path={OUTPUT_DIR}/OST_COMAPRE_LIGAND_STRUCTURES/{wildcards.multi}_seed-{wildcards.seed}_sample-{wildcards.sample}_score.json
        echo "ost compare-ligand-structures \
        -m {input.prediction} \
        -rl {input.ground_truth_sdf} \
        -r {input.ground_truth_cif} \
        -o $json_path \
        --lddt-pli --rmsd --lddt-pli-add-mdl-contacts -ft" > {output}
        """

rule AGG_OST_COMAPRE_LIGAND_STRUCTURES_JOBS:
    input:
        get_collect_predictions,        
    output:
        os.path.join(OUTPUT_DIR,"AGG_OST_COMAPRE_LIGAND_STRUCTURES_JOBS","jobs.txt")
    shell:
        """
        cat {input} > {output}
        """

rule SPLIT_OST_COMAPRE_LIGAND_STRUCTURES_JOBS:
    input:
         rules.AGG_OST_COMAPRE_LIGAND_STRUCTURES_JOBS.output if MODE == "virtual-drug-screen" and TASK=="ost" else [],
    params:
         split_ost = SPLIT_OST
    output:
         sub_job_list = scatter.split_ost(os.path.join(OUTPUT_DIR,"SPLIT_OST_COMAPRE_LIGAND_STRUCTURES_JOBS","job_{scatteritem}.txt"))
    run:
        import os
        lines = open(input[0]).readlines()
        [open(output.sub_job_list[i], "w").writelines(lines[i*len(lines)//params.split_ost:(i+1)*len(lines)//params.split_ost + (1 if i == 3 else 0)])
         for i in range(params.split_ost)]


rule OST_COMAPRE_LIGAND_STRUCTURES:
    input:
         sub_job_list = os.path.join(OUTPUT_DIR,"SPLIT_OST_COMAPRE_LIGAND_STRUCTURES_JOBS","job_{scatteritem}.txt") if MODE == "virtual-drug-screen" and TASK=="ost" else [],
    output:
         touch(os.path.join(OUTPUT_DIR,"OST_COMAPRE_LIGAND_STRUCTURES","done_flags","job_{scatteritem}.done.txt")),
    shell:
         """
         bash {WORKFLOW_DIR}/scripts/parallel_cpu.sh {input}
         """

rule CREATE_OST_REPORT:
    input:
         sub_job_list = os.path.join(OUTPUT_DIR,"SPLIT_OST_COMAPRE_LIGAND_STRUCTURES_JOBS","job_{scatteritem}.txt") if MODE == "virtual-drug-screen" and TASK=="ost" else [],
         done_file = os.path.join(OUTPUT_DIR,"OST_COMAPRE_LIGAND_STRUCTURES","done_flags","job_{scatteritem}.done.txt")
    output:
         os.path.join(OUTPUT_DIR,"CREATE_OST_REPORT","{scatteritem}_ost_report.csv")
    shell:
         """
         > {wildcards.scatteritem}.commands.sh
         grep -oP '(?<=-o )\\S+' {input.sub_job_list} | while read -r path; do echo "python {WORKFLOW_DIR}/scripts/af3_analysis.py.bak $path {RUNS_N_POSES_JSON_INPUTS} {OUTPUT_DIR}/AF3_INFERENCE {OUTPUT_DIR}/OST_COMAPRE_LIGAND_STRUCTURES {RUNS_N_POSES_ANNOTATIONS} >> {output}" >> {wildcards.scatteritem}.commands.sh; done
         chmod +x {wildcards.scatteritem}.commands.sh
         bash {WORKFLOW_DIR}/scripts/parallel_cpu.sh {wildcards.scatteritem}.commands.sh
         rm {wildcards.scatteritem}.commands.sh
         """

rule AGG_OST_REPORTS:
    input:
         expand(os.path.join(OUTPUT_DIR,"CREATE_OST_REPORT",f"{{s}}-of-{SPLIT_OST}_ost_report.csv"),s=list(range(1,SPLIT_OST+1))) if MODE == "virtual-drug-screen" and TASK=="ost" else [],
    output:
         os.path.join(OUTPUT_DIR,"AGG_OST_REPORTS","ost_report.csv")
    shell:
        """
        > {output}
        echo "target method seed sample ranking_score prot_lig_chain_iptm_average_lddt_pli prot_lig_chain_iptm_min_lddt_pli prot_lig_chain_iptm_max_lddt_pli lig_prot_chain_iptm_average_lddt_pli lig_prot_chain_iptm_min_lddt_pli lig_prot_chain_iptm_max_lddt_pli lddt_pli model_ligand_chain_lddt_pli model_ligand_ccd_code model_ligand_smiles ligand_ccd_code_x prot_lig_chain_iptm_average_rmsd prot_lig_chain_iptm_min_rmsd prot_lig_chain_iptm_max_rmsd lig_prot_chain_iptm_average_rmsd lig_prot_chain_iptm_min_rmsd lig_prot_chain_iptm_max_rmsd rmsd lddt_lp bb_rmsd model_ligand_chain_rmsd ligand_ccd_code_y ligand_instance_chain ligand_is_proper" > {output}
        cat {input} >> {output}
        """
